{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. Creating a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in ['2023-03']:\n",
    "  data_url = f'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{date}.parquet'\n",
    "  data_path = \"/\".join([\"data\", data_url.split('/')[-1]])\n",
    "  !mkdir -p 'data'\n",
    "  !curl -s -S $data_url -o $data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3403766"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_parquet, to_datetime\n",
    "\n",
    "df = read_parquet('./data/yellow_tripdata_2023-03.parquet')\n",
    "\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "  df.tpep_dropoff_datetime = to_datetime(df.tpep_dropoff_datetime)\n",
    "  df.tpep_pickup_datetime = to_datetime(df.tpep_pickup_datetime)\n",
    "\n",
    "  df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "  df.duration = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "  df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3316216"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = clean(df)\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5. Train a model\n",
    "\n",
    "Fit a dict vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "def transform(df):\n",
    "  dv = DictVectorizer()\n",
    "  \n",
    "  df[categorical] = df[categorical].astype(str)\n",
    "  train_dicts = df[categorical].to_dict(orient='records')\n",
    "  matrix = dv.fit_transform(train_dicts)\n",
    "\n",
    "  return dv, matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a dict vectorizer and a matrix of shape (n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv, x_train = transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a vector - the \"duration\" column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"duration\"\n",
    "y_train = df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def train_model(x_matrix, y_vector):\n",
    "  lr = LinearRegression()\n",
    "  lr.fit(x_matrix, y_vector)\n",
    "  return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a linear regression with default parameters and save the dict vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = train_model(x_train, y_train)\n",
    "lr.intercept_\n",
    "\n",
    "import pickle\n",
    "\n",
    "local_artifact_path = 'lin_reg.bin'\n",
    "\n",
    "with open(local_artifact_path, 'wb') as f_out:\n",
    "  pickle.dump(dv, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6. MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/04 01:10:52 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'numpy.ndarray' object has no attribute 'toarray'\n",
      "2024/06/04 01:11:39 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/Caskroom/miniconda/base/envs/ml-zoomcamp/lib/python3.9/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"my-experiment\")\n",
    "mlflow.sklearn.autolog()\n",
    "with mlflow.start_run():\n",
    "  lr = train_model(x_train, y_train)\n",
    "  mlflow.log_metric(\"intercept\", lr.intercept_)\n",
    "  mlflow.log_artifact(local_path=local_artifact_path, artifact_path=\"models_pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the model size from the artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<FileInfo: file_size=728, is_dir=False, path='model/MLmodel'>,\n",
       " <FileInfo: file_size=248, is_dir=False, path='model/conda.yaml'>,\n",
       " <FileInfo: file_size=None, is_dir=True, path='model/metadata'>,\n",
       " <FileInfo: file_size=4500, is_dir=False, path='model/model.pkl'>,\n",
       " <FileInfo: file_size=120, is_dir=False, path='model/python_env.yaml'>,\n",
       " <FileInfo: file_size=125, is_dir=False, path='model/requirements.txt'>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "mlclient = MlflowClient(\"sqlite:///backend.db\")\n",
    "runs = mlclient.search_runs(\n",
    "    experiment_ids=\"1\",\n",
    "    filter_string=\"\",\n",
    "    max_results=1\n",
    ")\n",
    "mlclient.list_artifacts(run_id=runs[0].info.run_id, path=\"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
